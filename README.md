# Exploiting Deep Reinforcement Learning for Edge Caching in Cell-Free Massive MIMO Systems

This is a code package is related to the following scientific article:

Yu Zhang, Shuaifei Chen, and Jiayi Zhang, "[Exploiting Deep Reinforcement Learning for Edge Caching in Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2208.12453)," *IEEE Global Communications Conference*, December 2022.

The package contains a simulation environment, based on Matlab and Python that reproduces some of the numerical results and figures in the article. *We encourage you to also perform reproducible research!*


## Abstract of Article

Cell-free massive multiple-input-multiple-output is promising to meet the stringent quality-of-experience (QoE) requirements of railway wireless communications by coordinating many successional access points (APs) to serve the onboard users coherently. A key challenge is how to deliver the desired contents timely due to the radical changing propagation environment caused by the growing train speed. In this paper, we propose to proactively cache the likely-requesting contents at the upcoming APs which perform the coherent transmission to reduce end-to-end delay. A long-term QoE-maximization problem is formulated and two cache placement algorithms are proposed. One is based on heuristic convex optimization (HCO) and the other exploits deep reinforcement learning (DRL) with soft actor-critic (SAC). Compared to the conventional benchmark, numerical results show the advantage of our proposed algorithms on QoE and hit probability. With the advanced DRL model, SAC outperforms HCO on QoE by predicting the user requests accurately.


## Content of Code Package

The package generates the simulation results which are used in Figure 3, Figure 4, and Figure 5. To be specific:

- `Python`: Generate the entire deep reinforcement learning model and simulation data;
  * `contrast`: Perform the three algorithms in the paper and generate the simulation data;
  * `environment`: Model our problem as an environment for deep reinforcement learning to perform under the *Stable Baseline 3*;
  * `test`: Compute simulation QoE and hit probabilities results;
  * `time`: Compute simulation running time results;
- `Matlab`: Exploiting the data given by `Python` to generate the figure of CDFs;
  * `CDF`: Generate the figure of the CDFs about QoE and hit probabilities;
  * `CDF_time`: Generate the figure of the CDFs about running times;
- `data`: This is the data generated by `Python` for the figure of CDFs;
  - `CDF`: Be used to generate the figure of the CDFs about QoE and hit probabilities;
  - `time`: Be used to generate the figure of the CDFs about running times;
  - `SAC`: This is the deep reinforcement learning model generated by *Stable Baseline 3*;


## License and Referencing

This code package is licensed under the GPLv2 license. If you in any way use this code for research that results in publications, please cite our original article listed above.
